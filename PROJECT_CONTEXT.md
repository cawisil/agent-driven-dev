# Project Context

<!-- FÃ¼lle dieses Dokument mit deinen projektspezifischen Informationen aus.
     Claude liest diese Datei automatisch und nutzt den Kontext fÃ¼r bessere Antworten. -->

## Projekt-Ãœbersicht

**Name:** [Dein Projektname]
**Beschreibung:** [Was baut dieses Projekt? Was ist das Ziel?]
**Status:** In Entwicklung

## Ziele & Vision

[Was willst du mit diesem AI-Workflow erreichen?]

Beispiele:
- Automatische Zusammenfassung von Research-Papieren
- Lokaler AI-Assistent fÃ¼r Dokument-Analyse
- Pipeline zur Datenextraktion und -anreicherung

## Tech-Stack

- **Sprache:** Python 3.12+
- **LLM:** [z.B. Claude (Anthropic API) / Ollama lokal / Gemini]
- **Key Libraries:** [z.B. anthropic, langchain, pandas, etc.]
- **Datenspeicherung:** [z.B. SQLite / JSON-Files / Chroma Vektordatenbank]

## Projektstruktur

```
project/
â”œâ”€â”€ .claude/agents/          # AI-Agenten fÃ¼r den Entwicklungs-Workflow
â”œâ”€â”€ features/                # Feature Specifications (PROJ-X.md)
â”œâ”€â”€ src/                     # Python-Quellcode
â”‚   â””â”€â”€ [module]/
â”œâ”€â”€ tests/                   # pytest Tests
â”œâ”€â”€ .env                     # Lokale API-Keys (NICHT ins Git!)
â”œâ”€â”€ .env.example             # Template fÃ¼r API-Keys
â””â”€â”€ requirements.txt         # Python-Dependencies
```

## Aktuelle Features

| Feature | Status | Beschreibung |
|---------|--------|-------------|
| -       | ğŸ”µ Planned | - |

### Status-Legende
- ğŸ”µ Planned â€” Spec geschrieben, noch nicht started
- ğŸŸ¡ In Progress â€” In Entwicklung
- ğŸŸ¢ Done â€” Implementiert und getestet
- âŒ Blocked â€” Blockiert durch Dependency

## Bekannte EinschrÃ¤nkungen / Tech-Schulden

[Dokumentiere hier bekannte Probleme oder temporÃ¤re LÃ¶sungen]

## NÃ¼tzliche Befehle

```bash
# Virtuelle Umgebung
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Dependencies installieren
pip install -r requirements.txt

# Tests ausfÃ¼hren
pytest tests/ -v
pytest tests/ -v -m "not integration"  # Ohne echte API-Calls

# Ollama (lokale Modelle)
ollama serve                 # Server starten
ollama pull llama3.2         # Modell herunterladen
ollama list                  # VerfÃ¼gbare Modelle
```

## API-Keys & Konfiguration

BenÃ¶tigte Environment Variables (in `.env`):

```bash
# Anthropic Claude API
ANTHROPIC_API_KEY=sk-ant-...

# Optional: Weitere Services
OPENAI_API_KEY=sk-...
OLLAMA_BASE_URL=http://localhost:11434
```
